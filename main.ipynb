{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE4483 Mini Project (Option 2): Cats vs Dogs\n",
    "\n",
    "Name: Melvin Kok Xinwei<br>\n",
    "Matriculation Number: U1820030C\n",
    "\n",
    "## Overview\n",
    "1. Data exploration\n",
    "2. Loading and processing data\n",
    "3. Model selection\n",
    "4. Model training\n",
    "5. Model testing\n",
    "6. CIFAR-10 training\n",
    "7. CIFAR-10 testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from pandas.core.common import flatten\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "separator = os.path.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"lr\": 0.001,\n",
    "    \"batch_size\": 64,\n",
    "    \"n_epochs\": 10,\n",
    "    \"image_size\": 224,\n",
    "    \"dropout_rate\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data exploration\n",
    "\n",
    "Place `datasets` in same directory as notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define main directories\n",
    "base_dir = \"datasets\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "validation_dir = os.path.join(base_dir, \"val\")\n",
    "test_dir = os.path.join(base_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_image_path example:  datasets\\train\\cat\\cat.3532.jpg\n",
      "validation_image_path example:  datasets\\val\\dog\\dog.7569.jpg\n",
      "test_image_path example:  datasets\\test\\1.jpg\n"
     ]
    }
   ],
   "source": [
    "# Paths for training images\n",
    "train_image_paths = []\n",
    "train_classes = {}\n",
    "\n",
    "for data_path in glob.glob(train_dir + separator + \"*\"):\n",
    "    images = glob.glob(data_path + separator + \"*\")\n",
    "    train_classes[data_path.split(separator)[-1]] = len(images)\n",
    "    train_image_paths.append(images)\n",
    "\n",
    "train_image_paths = list(flatten(train_image_paths))\n",
    "random.shuffle(train_image_paths)\n",
    "\n",
    "# Paths for validation images\n",
    "validation_image_paths = []\n",
    "validation_classes = {}\n",
    "\n",
    "for data_path in glob.glob(validation_dir + separator + \"*\"):\n",
    "    images = glob.glob(data_path + separator + \"*\")\n",
    "    validation_classes[data_path.split(separator)[-1]] = len(images)\n",
    "    validation_image_paths.append(images)\n",
    "\n",
    "validation_image_paths = list(flatten(validation_image_paths))\n",
    "random.shuffle(validation_image_paths)\n",
    "\n",
    "# Paths for test images\n",
    "test_image_paths = []\n",
    "for data_path in glob.glob(test_dir + separator + \"*\"):\n",
    "    test_image_paths.append(data_path)\n",
    "\n",
    "test_image_paths = list(flatten(test_image_paths))\n",
    "\n",
    "print(\"train_image_path example: \", train_image_paths[0])\n",
    "print(\"validation_image_path example: \", validation_image_paths[0])\n",
    "print(\"test_image_path example: \", test_image_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class cat, data size 10000\n",
      "Train class dog, data size 10000\n",
      "Validation class cat, data size 2500\n",
      "Validation class dog, data size 2500\n",
      "Test size: 500\n"
     ]
    }
   ],
   "source": [
    "for key, value in train_classes.items():\n",
    "    print(f\"Train class {key}, data size {value}\")\n",
    "\n",
    "for key, value in validation_classes.items():\n",
    "    print(f\"Validation class {key}, data size {value}\")\n",
    "\n",
    "print(f\"Test size: {len(test_image_paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading and processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to id mappings\n",
    "class_to_id = {\"cat\": 0, \"dog\": 1}\n",
    "\n",
    "# Custom Dataset class\n",
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self, image_paths, class_to_id, transform=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        self.class_to_id = class_to_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        label = image_filepath.split(separator)[-2]\n",
    "        label = self.class_to_id[label]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:58<00:00, 168.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48846444487571716, 0.45509541034698486, 0.4170514643192291]\n",
      "[0.23550903797149658, 0.23108406364917755, 0.23146183788776398]\n"
     ]
    }
   ],
   "source": [
    "# Pre-calculated values, use this to save on time\n",
    "# mean = [0.48846444487571716, 0.45509546995162964, 0.4170514643192291]\n",
    "# std = [0.23550905287265778, 0.23108406364917755, 0.23146183788776398]\n",
    "\n",
    "# Get mean and std of dataset\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = CatDogDataset(train_image_paths, class_to_id, transform)\n",
    "\n",
    "means = []\n",
    "vars = []\n",
    "for img, _ in tqdm(dataset):\n",
    "    means.append(torch.mean(img, [1, 2]))\n",
    "    vars.append(torch.var(img, [1, 2]))\n",
    "\n",
    "mean = torch.mean(torch.stack(means), 0)\n",
    "var = torch.mean(torch.stack(vars), 0)\n",
    "std = torch.sqrt(var)\n",
    "\n",
    "mean = mean.tolist()\n",
    "std = std.tolist()\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image augmentations and pre-processing\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomResizedCrop(params[\"image_size\"]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "validation_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((params[\"image_size\"], params[\"image_size\"])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CatDogDataset(train_image_paths, class_to_id, train_transform)\n",
    "valid_dataset = CatDogDataset(validation_image_paths, class_to_id, validation_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=params[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace=True)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cat_dog_model = torchvision.models.vgg19(pretrained=True)\n",
    "print(cat_dog_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze layers in model\n",
    "for param in cat_dog_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "cat_dog_model.classifier = torch.nn.Sequential(torch.nn.Linear(25088, 4096),\n",
    "                                               torch.nn.ReLU(),\n",
    "                                               torch.nn.Dropout(p=params[\"dropout_rate\"]),\n",
    "                                               torch.nn.Linear(4096, 4096),\n",
    "                                               torch.nn.ReLU(),\n",
    "                                               torch.nn.Dropout(p=params[\"dropout_rate\"]),\n",
    "                                               torch.nn.Linear(4096, 2))\n",
    "\n",
    "# Unfreeze classifier\n",
    "for param in cat_dog_model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model = copy.deepcopy(cat_dog_model)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "probs = torch.nn.Softmax(dim=1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.classifier.parameters(), lr=params[\"lr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 313/313 [02:43<00:00,  1.92batch/s, loss=0.261]\n",
      "Epoch 1/10: 100%|██████████| 79/79 [00:37<00:00,  2.12batch/s, loss=0.174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 avg Valid loss: 0.103\n",
      "Epoch 1 Valid accuracy: 98.2% (4908 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 313/313 [02:39<00:00,  1.96batch/s, loss=0.137]\n",
      "Epoch 2/10: 100%|██████████| 79/79 [00:37<00:00,  2.12batch/s, loss=0.068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 avg Valid loss: 0.050\n",
      "Epoch 2 Valid accuracy: 98.6% (4930 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 313/313 [02:39<00:00,  1.96batch/s, loss=0.207]\n",
      "Epoch 3/10: 100%|██████████| 79/79 [00:37<00:00,  2.11batch/s, loss=0.0362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 avg Valid loss: 0.038\n",
      "Epoch 3 Valid accuracy: 98.8% (4941 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 313/313 [02:39<00:00,  1.96batch/s, loss=0.126]\n",
      "Epoch 4/10: 100%|██████████| 79/79 [00:37<00:00,  2.12batch/s, loss=0.0221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 avg Valid loss: 0.033\n",
      "Epoch 4 Valid accuracy: 98.9% (4944 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 313/313 [02:39<00:00,  1.96batch/s, loss=0.109]\n",
      "Epoch 5/10: 100%|██████████| 79/79 [00:37<00:00,  2.12batch/s, loss=0.0151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 avg Valid loss: 0.031\n",
      "Epoch 5 Valid accuracy: 98.9% (4945 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 313/313 [02:39<00:00,  1.96batch/s, loss=0.059]\n",
      "Epoch 6/10: 100%|██████████| 79/79 [00:37<00:00,  2.12batch/s, loss=0.012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 avg Valid loss: 0.030\n",
      "Epoch 6 Valid accuracy: 99.0% (4948 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 313/313 [02:39<00:00,  1.97batch/s, loss=0.066]\n",
      "Epoch 7/10: 100%|██████████| 79/79 [00:37<00:00,  2.13batch/s, loss=0.0118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 avg Valid loss: 0.030\n",
      "Epoch 7 Valid accuracy: 99.0% (4950 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 313/313 [02:39<00:00,  1.96batch/s, loss=0.0664]\n",
      "Epoch 8/10: 100%|██████████| 79/79 [00:37<00:00,  2.13batch/s, loss=0.0083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 avg Valid loss: 0.029\n",
      "Epoch 8 Valid accuracy: 99.0% (4950 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 313/313 [02:39<00:00,  1.96batch/s, loss=0.17]\n",
      "Epoch 9/10: 100%|██████████| 79/79 [00:37<00:00,  2.12batch/s, loss=0.0088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 avg Valid loss: 0.029\n",
      "Epoch 9 Valid accuracy: 99.0% (4948 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 313/313 [02:39<00:00,  1.96batch/s, loss=0.197]\n",
      "Epoch 10/10: 100%|██████████| 79/79 [00:37<00:00,  2.12batch/s, loss=0.00643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 avg Valid loss: 0.028\n",
      "Epoch 10 Valid accuracy: 98.9% (4945 of 5000 right)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "valid_acc = []\n",
    "for epoch in range(params[\"n_epochs\"]):\n",
    "    # Train\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    with tqdm(enumerate(train_loader), total=len(train_loader), unit=\"batch\") as pbar:\n",
    "        for step, (imgs, labels) in pbar:\n",
    "            pbar.set_description(f\"Epoch {epoch+1}/{params['n_epochs']}\")\n",
    "\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            log_preds = model(imgs)\n",
    "            loss = loss_fn(log_preds, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += ((1 / (step + 1)) * (loss.data.item() - train_loss))\n",
    "\n",
    "            pbar.set_postfix(loss=loss.data.item())\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation\n",
    "    valid_loss = 0\n",
    "    actual_labels = []\n",
    "    pred_labels = []\n",
    "    model.eval()\n",
    "    with tqdm(enumerate(valid_loader), total=len(valid_loader), unit=\"batch\") as pbar:\n",
    "        for step, (imgs, labels) in pbar:\n",
    "            pbar.set_description(f\"Epoch {epoch+1}/{params['n_epochs']}\")  \n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            log_preds = model(imgs)\n",
    "            loss = loss_fn(log_preds, labels)\n",
    "            preds = probs(log_preds)\n",
    "\n",
    "            valid_loss+=((1 / (step + 1)) * (loss.data.item() - valid_loss))\n",
    "\n",
    "            # Calculate accuracy\n",
    "            top_prob, top_class = preds.topk(1, dim=1)\n",
    "            pred_labels+= list((top_class.view(-1)).cpu().numpy())\n",
    "            actual_labels+= list(labels.cpu().numpy())\n",
    "\n",
    "            pbar.set_postfix(loss=loss.data.item())\n",
    "\n",
    "        correct = ((np.array(pred_labels)==np.array(actual_labels)).sum())\n",
    "        total = len(valid_dataset)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        tqdm.write(\"Epoch {} avg Valid loss: {:.3f}\".format(epoch + 1, valid_loss))\n",
    "        tqdm.write(\"Epoch {} Valid accuracy: {:.1%} ({} of {} right)\\n\".format(epoch + 1, accuracy, correct, total))\n",
    "\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_acc.append(accuracy)\n",
    "\n",
    "    # Save model if validation loss is the lowest\n",
    "    if len(valid_losses)>1 and (valid_loss<min(valid_losses[:-1])):\n",
    "        torch.save(model.state_dict(), f\"models/{params['lr']}_{params['image_size']}_{params['n_epochs']}_{params['dropout_rate']}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(range(1, params[\"n_epochs\"]+1), train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(1, params[\"n_epochs\"]+1), valid_losses, label=\"Validation Loss\")\n",
    "plt.plot(range(1, params[\"n_epochs\"]+1), valid_acc, label=\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"models/{params['lr']}_{params['image_size']}_{params['n_epochs']}_{params['dropout_rate']}.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:37<00:00,  2.12batch/s, loss=0.00643]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.028\n",
      "Valid accuracy: 98.9% (4945 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "running_loss = 0\n",
    "actual_labels = []\n",
    "pred_labels = []\n",
    "with tqdm(enumerate(valid_loader), total=len(valid_loader), unit=\"batch\") as pbar:\n",
    "    for step, (imgs, labels) in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        log_preds = model(imgs)\n",
    "        loss = loss_fn(log_preds, labels)\n",
    "\n",
    "        preds = probs(log_preds)\n",
    "        running_loss += ((1 / (step + 1)) * (loss.data.item() - running_loss))\n",
    "\n",
    "        # Calculate accuracy\n",
    "        top_prob, top_class = preds.topk(1, dim=1)\n",
    "        pred_labels += list((top_class.view(-1)).cpu().numpy())\n",
    "        actual_labels += list(labels.cpu().numpy())\n",
    "\n",
    "        pbar.set_postfix(loss=loss.data.item())\n",
    "\n",
    "    correct = ((np.array(pred_labels)==np.array(actual_labels)).sum())\n",
    "    total = len(actual_labels)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    tqdm.write(\"Valid loss: {:.3f}\".format(running_loss))\n",
    "    tqdm.write(\"Valid accuracy: {:.1%} ({} of {} right)\\n\".format(accuracy, correct, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class for test data\n",
    "class TestCatDogDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image_filename = Path(image_filepath).stem\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, image_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestCatDogDataset(test_image_paths, validation_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=params[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.01batch/s]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "pred_labels = []\n",
    "filename = []\n",
    "with tqdm(test_loader, total=len(test_loader), unit=\"batch\") as pbar:\n",
    "    for imgs, filenames in pbar:\n",
    "        imgs = imgs.to(device)\n",
    "        log_preds = model(imgs)\n",
    "\n",
    "        preds = probs(log_preds)\n",
    "\n",
    "        top_prob, top_class = preds.topk(1, dim=1)\n",
    "        pred_labels += list((top_class.view(-1)).cpu().numpy())\n",
    "        filename += filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(filename, pred_labels)),\n",
    "               columns=[\"id\", \"label\"])\n",
    "df[\"id\"] = pd.to_numeric(df[\"id\"])\n",
    "df = df.sort_values(by=[\"id\"])\n",
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. CIFAR-10 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.Resize((params[\"image_size\"], params[\"image_size\"])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "validation_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((params[\"image_size\"], params[\"image_size\"])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=params[\"batch_size\"],\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=False,\n",
    "                                       download=True, transform=validation_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=params[\"batch_size\"],\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(cat_dog_model)\n",
    "model.classifier = torch.nn.Sequential(torch.nn.Linear(25088, 4096),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Dropout(p=params[\"dropout_rate\"]),\n",
    "                                       torch.nn.Linear(4096, 4096),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Dropout(p=params[\"dropout_rate\"]),\n",
    "                                       torch.nn.Linear(4096, 10))\n",
    "model.to(device)\n",
    "\n",
    "probs = torch.nn.Softmax(dim=1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.classifier.parameters(), lr=params[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 782/782 [04:22<00:00,  2.98batch/s, loss=1.87]\n",
      "Epoch 1/10: 100%|██████████| 157/157 [00:49<00:00,  3.14batch/s, loss=1.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 avg Valid loss: 1.743\n",
      "Epoch 1 Valid accuracy: 56.1% (5610 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 782/782 [04:22<00:00,  2.98batch/s, loss=1.27]\n",
      "Epoch 2/10: 100%|██████████| 157/157 [00:50<00:00,  3.14batch/s, loss=1.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 avg Valid loss: 1.092\n",
      "Epoch 2 Valid accuracy: 71.0% (7103 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 782/782 [04:22<00:00,  2.97batch/s, loss=0.814]\n",
      "Epoch 3/10: 100%|██████████| 157/157 [00:49<00:00,  3.14batch/s, loss=0.778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 avg Valid loss: 0.782\n",
      "Epoch 3 Valid accuracy: 77.5% (7749 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 782/782 [04:22<00:00,  2.98batch/s, loss=0.671]\n",
      "Epoch 4/10: 100%|██████████| 157/157 [00:49<00:00,  3.14batch/s, loss=0.594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 avg Valid loss: 0.644\n",
      "Epoch 4 Valid accuracy: 79.8% (7985 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 782/782 [04:24<00:00,  2.96batch/s, loss=0.925]\n",
      "Epoch 5/10: 100%|██████████| 157/157 [00:49<00:00,  3.14batch/s, loss=0.511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 avg Valid loss: 0.571\n",
      "Epoch 5 Valid accuracy: 81.5% (8153 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 782/782 [04:22<00:00,  2.98batch/s, loss=0.551]\n",
      "Epoch 6/10: 100%|██████████| 157/157 [00:50<00:00,  3.14batch/s, loss=0.441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 avg Valid loss: 0.526\n",
      "Epoch 6 Valid accuracy: 82.7% (8274 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 782/782 [04:23<00:00,  2.97batch/s, loss=0.418]\n",
      "Epoch 7/10: 100%|██████████| 157/157 [00:49<00:00,  3.14batch/s, loss=0.389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 avg Valid loss: 0.499\n",
      "Epoch 7 Valid accuracy: 83.2% (8315 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 782/782 [04:22<00:00,  2.97batch/s, loss=0.512]\n",
      "Epoch 8/10: 100%|██████████| 157/157 [00:49<00:00,  3.14batch/s, loss=0.375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 avg Valid loss: 0.479\n",
      "Epoch 8 Valid accuracy: 83.4% (8343 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 782/782 [04:22<00:00,  2.98batch/s, loss=0.657]\n",
      "Epoch 9/10: 100%|██████████| 157/157 [00:49<00:00,  3.14batch/s, loss=0.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 avg Valid loss: 0.462\n",
      "Epoch 9 Valid accuracy: 83.9% (8392 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 782/782 [04:22<00:00,  2.98batch/s, loss=0.291]\n",
      "Epoch 10/10: 100%|██████████| 157/157 [00:49<00:00,  3.14batch/s, loss=0.349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 avg Valid loss: 0.448\n",
      "Epoch 10 Valid accuracy: 84.4% (8436 of 10000 right)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "valid_acc = []\n",
    "for epoch in range(params[\"n_epochs\"]):\n",
    "    # Train\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    with tqdm(enumerate(train_loader), total=len(train_loader), unit=\"batch\") as pbar:\n",
    "        for step, (imgs, labels) in pbar:\n",
    "            pbar.set_description(\"Epoch {}/{}\".format(epoch+1, params[\"n_epochs\"]))\n",
    "\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            log_preds = model(imgs)\n",
    "            loss = loss_fn(log_preds, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += ((1 / (step + 1)) * (loss.data.item() - train_loss))\n",
    "\n",
    "            pbar.set_postfix(loss=loss.data.item())\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation\n",
    "    valid_loss = 0\n",
    "    actual_labels = []\n",
    "    pred_labels = []\n",
    "    model.eval()\n",
    "    with tqdm(enumerate(test_loader), total=len(test_loader), unit=\"batch\") as pbar:\n",
    "        for step, (imgs, labels) in pbar:\n",
    "            pbar.set_description(f\"Epoch {epoch+1}/{params['n_epochs']}\")  \n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            log_preds = model(imgs)\n",
    "            loss = loss_fn(log_preds, labels)\n",
    "\n",
    "            preds = probs(log_preds)\n",
    "            valid_loss+=((1 / (step + 1)) * (loss.data.item() - valid_loss))\n",
    "\n",
    "            # Calculate accuracy\n",
    "            top_prob, top_class = preds.topk(1, dim=1)\n",
    "            pred_labels+= list((top_class.view(-1)).cpu().numpy())\n",
    "            actual_labels+= list(labels.cpu().numpy())\n",
    "\n",
    "            pbar.set_postfix(loss=loss.data.item())\n",
    "\n",
    "        correct = (np.array(pred_labels)==np.array(actual_labels)).sum()\n",
    "        total = len(actual_labels)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        tqdm.write(\"Epoch {} avg Valid loss: {:.3f}\".format(epoch + 1, valid_loss))\n",
    "        tqdm.write(\"Epoch {} Valid accuracy: {:.1%} ({} of {} right)\\n\".format(epoch + 1, accuracy, correct, total))\n",
    "\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_acc.append(accuracy)\n",
    "\n",
    "    if len(valid_losses)>1 and (valid_loss<min(valid_losses[:-1])):\n",
    "        torch.save(model.state_dict(), f\"models/cifar_10_{params['lr']}_{params['image_size']}_{params['n_epochs']}_{params['dropout_rate']}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(range(1, params[\"n_epochs\"]+1), train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(1, params[\"n_epochs\"]+1), valid_losses, label=\"Validation Loss\")\n",
    "plt.plot(range(1, params[\"n_epochs\"]+1), valid_acc, label=\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. CIFAR-10 testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"models/cifar_10_{params['lr']}_{params['image_size']}_{params['n_epochs']}_{params['dropout_rate']}.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:51<00:00,  3.07batch/s]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "model.eval()\n",
    "\n",
    "with tqdm(test_loader, total=len(test_loader), unit=\"batch\") as pbar:\n",
    "    for imgs, labels in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        log_preds = model(imgs)\n",
    "        loss = loss_fn(log_preds, labels)\n",
    "\n",
    "        preds = probs(log_preds)\n",
    "\n",
    "        top_prob, top_class = preds.topk(1, dim=1)\n",
    "\n",
    "        for label, prediction in zip(labels, top_class):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plane': 846, 'car': 920, 'bird': 746, 'cat': 725, 'deer': 829, 'dog': 769, 'frog': 913, 'horse': 855, 'ship': 925, 'truck': 908}\n",
      "{'plane': 1000, 'car': 1000, 'bird': 1000, 'cat': 1000, 'deer': 1000, 'dog': 1000, 'frog': 1000, 'horse': 1000, 'ship': 1000, 'truck': 1000}\n"
     ]
    }
   ],
   "source": [
    "print(correct_pred)\n",
    "print(total_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class plane is: 84.6 %\n",
      "Accuracy for class car   is: 92.0 %\n",
      "Accuracy for class bird  is: 74.6 %\n",
      "Accuracy for class cat   is: 72.5 %\n",
      "Accuracy for class deer  is: 82.9 %\n",
      "Accuracy for class dog   is: 76.9 %\n",
      "Accuracy for class frog  is: 91.3 %\n",
      "Accuracy for class horse is: 85.5 %\n",
      "Accuracy for class ship  is: 92.5 %\n",
      "Accuracy for class truck is: 90.8 %\n",
      "Test accuracy: 84.4% (8436 of 10000 right)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname, accuracy))\n",
    "\n",
    "correct = sum(correct_pred.values())\n",
    "total = sum(total_pred.values())\n",
    "accuracy = correct / total\n",
    "\n",
    "print(\"Test accuracy: {:.1%} ({} of {} right)\\n\".format(accuracy, correct, total))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89ea3e921d5f22d2b46ed8b2b66b1aa063d1552fc9c096c0e74c45a505ca44a9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
