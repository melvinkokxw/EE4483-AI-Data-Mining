{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE4483 Mini Project (Option 2): Cats vs Dogs\n",
    "\n",
    "Name: Melvin Kok Xinwei\n",
    "Matriculation Number: U1820030C\n",
    "\n",
    "## Overview\n",
    "1. Data exploration\n",
    "2. Loading and processing data\n",
    "3. Model selection\n",
    "4. Model training\n",
    "5. Model testing\n",
    "6. CIFAR-10 training\n",
    "7. CIFAR-10 testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from pandas.core.common import flatten\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "separator = os.path.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"lr\": 0.001,\n",
    "    \"batch_size\": 64,\n",
    "    \"n_epochs\": 10,\n",
    "    \"image_size\": 224,\n",
    "    \"dropout_rate\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data exploration\n",
    "\n",
    "Place `datasets` in same directory as notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define main directories\n",
    "base_dir = \"datasets\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "validation_dir = os.path.join(base_dir, \"val\")\n",
    "test_dir = os.path.join(base_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_image_path example:  datasets\\train\\cat\\cat.7784.jpg\n",
      "validation_image_path example:  datasets\\val\\cat\\cat.4347.jpg\n",
      "test_image_path example:  datasets\\test\\1.jpg\n"
     ]
    }
   ],
   "source": [
    "# Paths for training images\n",
    "train_image_paths = []\n",
    "train_classes = {}\n",
    "\n",
    "for data_path in glob.glob(train_dir + separator + \"*\"):\n",
    "    images = glob.glob(data_path + separator + \"*\")\n",
    "    train_classes[data_path.split(separator)[-1]] = len(images)\n",
    "    train_image_paths.append(images)\n",
    "\n",
    "train_image_paths = list(flatten(train_image_paths))\n",
    "random.shuffle(train_image_paths)\n",
    "\n",
    "# Paths for validation images\n",
    "validation_image_paths = []\n",
    "validation_classes = {}\n",
    "\n",
    "for data_path in glob.glob(validation_dir + separator + \"*\"):\n",
    "    images = glob.glob(data_path + separator + \"*\")\n",
    "    validation_classes[data_path.split(separator)[-1]] = len(images)\n",
    "    validation_image_paths.append(images)\n",
    "\n",
    "validation_image_paths = list(flatten(validation_image_paths))\n",
    "random.shuffle(validation_image_paths)\n",
    "\n",
    "# Paths for test images\n",
    "test_image_paths = []\n",
    "for data_path in glob.glob(test_dir + separator + \"*\"):\n",
    "    test_image_paths.append(data_path)\n",
    "\n",
    "test_image_paths = list(flatten(test_image_paths))\n",
    "\n",
    "print(\"train_image_path example: \", train_image_paths[0])\n",
    "print(\"validation_image_path example: \", validation_image_paths[0])\n",
    "print(\"test_image_path example: \", test_image_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class cat, data size 10000\n",
      "Train class dog, data size 10000\n",
      "Validation class cat, data size 2500\n",
      "Validation class dog, data size 2500\n",
      "Test size: 500\n"
     ]
    }
   ],
   "source": [
    "for key, value in train_classes.items():\n",
    "    print(f\"Train class {key}, data size {value}\")\n",
    "\n",
    "for key, value in validation_classes.items():\n",
    "    print(f\"Validation class {key}, data size {value}\")\n",
    "\n",
    "print(f\"Test size: {len(test_image_paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading and processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to index mappings\n",
    "idx_to_class = {i:j for i, j in enumerate(train_classes)}\n",
    "class_to_idx = {value:key for key,value in idx_to_class.items()}\n",
    "\n",
    "# Custom Dataset class\n",
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self, image_paths, class_to_idx, transform=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = class_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        label = image_filepath.split(separator)[-2]\n",
    "        label = self.class_to_idx[label]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-calculated values, use this to save on time\n",
    "# mean = [0.48846444487571716, 0.45509546995162964, 0.4170514643192291]\n",
    "# std = [0.23550905287265778, 0.23108406364917755, 0.23146183788776398]\n",
    "\n",
    "# Get mean and std of dataset\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = CatDogDataset(train_image_paths, class_to_idx, transform)\n",
    "\n",
    "means = []\n",
    "vars = []\n",
    "for img, _ in tqdm(dataset):\n",
    "    means.append(torch.mean(img, [1, 2]))\n",
    "    vars.append(torch.var(img, [1, 2]))\n",
    "\n",
    "mean = torch.mean(torch.stack(means), 0)\n",
    "var = torch.mean(torch.stack(vars), 0)\n",
    "std = torch.sqrt(var)\n",
    "\n",
    "mean = mean.tolist()\n",
    "std = std.tolist()\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image augmentations and pre-processing\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomResizedCrop(params[\"image_size\"]),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "validation_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((params[\"image_size\"], params[\"image_size\"])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CatDogDataset(train_image_paths, class_to_idx, train_transform)\n",
    "valid_dataset = CatDogDataset(validation_image_paths, class_to_idx, validation_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=params[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace=True)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cat_dog_model = torchvision.models.vgg19(pretrained=True)\n",
    "print(cat_dog_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze layers in model\n",
    "for param in cat_dog_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "cat_dog_model.classifier = torch.nn.Sequential(torch.nn.Linear(25088, 4096),\n",
    "                                               torch.nn.ReLU(),\n",
    "                                               torch.nn.Dropout(p=params[\"dropout_rate\"]),\n",
    "                                               torch.nn.Linear(4096, 4096),\n",
    "                                               torch.nn.ReLU(),\n",
    "                                               torch.nn.Dropout(p=params[\"dropout_rate\"]),\n",
    "                                               torch.nn.Linear(4096, 2))\n",
    "\n",
    "# Unfreeze classifier\n",
    "for param in cat_dog_model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model = copy.deepcopy(cat_dog_model)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "probs = torch.nn.Softmax(dim=1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.classifier.parameters(), lr=params[\"lr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 313/313 [02:50<00:00,  1.84batch/s, loss=0.197]\n",
      "Epoch 1/10: 100%|██████████| 79/79 [00:41<00:00,  1.92batch/s, loss=0.159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 avg Valid loss: 0.098\n",
      "Epoch 1 Valid accuracy: 98.3% (4915 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 313/313 [02:37<00:00,  1.99batch/s, loss=0.216]\n",
      "Epoch 2/10: 100%|██████████| 79/79 [00:38<00:00,  2.06batch/s, loss=0.114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 avg Valid loss: 0.050\n",
      "Epoch 2 Valid accuracy: 98.5% (4927 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 313/313 [02:36<00:00,  2.00batch/s, loss=0.411]\n",
      "Epoch 3/10: 100%|██████████| 79/79 [00:38<00:00,  2.05batch/s, loss=0.108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 avg Valid loss: 0.038\n",
      "Epoch 3 Valid accuracy: 98.7% (4937 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 313/313 [02:38<00:00,  1.98batch/s, loss=0.0208]\n",
      "Epoch 4/10: 100%|██████████| 79/79 [00:38<00:00,  2.03batch/s, loss=0.0989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 avg Valid loss: 0.034\n",
      "Epoch 4 Valid accuracy: 98.9% (4946 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 313/313 [02:37<00:00,  1.99batch/s, loss=0.198]\n",
      "Epoch 5/10: 100%|██████████| 79/79 [00:39<00:00,  2.02batch/s, loss=0.0804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 avg Valid loss: 0.031\n",
      "Epoch 5 Valid accuracy: 99.0% (4949 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 313/313 [02:36<00:00,  2.00batch/s, loss=0.131]\n",
      "Epoch 6/10: 100%|██████████| 79/79 [00:39<00:00,  2.00batch/s, loss=0.0496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 avg Valid loss: 0.030\n",
      "Epoch 6 Valid accuracy: 99.0% (4949 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 313/313 [02:36<00:00,  2.00batch/s, loss=0.116]\n",
      "Epoch 7/10: 100%|██████████| 79/79 [00:38<00:00,  2.07batch/s, loss=0.0478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 avg Valid loss: 0.029\n",
      "Epoch 7 Valid accuracy: 98.9% (4945 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 313/313 [02:35<00:00,  2.01batch/s, loss=0.108]\n",
      "Epoch 8/10: 100%|██████████| 79/79 [00:39<00:00,  2.01batch/s, loss=0.045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 avg Valid loss: 0.028\n",
      "Epoch 8 Valid accuracy: 98.9% (4946 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 313/313 [02:41<00:00,  1.94batch/s, loss=0.0865]\n",
      "Epoch 9/10: 100%|██████████| 79/79 [00:40<00:00,  1.97batch/s, loss=0.0382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 avg Valid loss: 0.028\n",
      "Epoch 9 Valid accuracy: 98.9% (4946 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 313/313 [02:40<00:00,  1.95batch/s, loss=0.0513]\n",
      "Epoch 10/10: 100%|██████████| 79/79 [00:39<00:00,  2.01batch/s, loss=0.0357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 avg Valid loss: 0.028\n",
      "Epoch 10 Valid accuracy: 99.0% (4949 of 5000 right)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "valid_acc = []\n",
    "for epoch in range(params[\"n_epochs\"]):\n",
    "    # Train\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    with tqdm(enumerate(train_loader), total=len(train_loader), unit=\"batch\") as pbar:\n",
    "        for step, (imgs, labels) in pbar:\n",
    "            pbar.set_description(f\"Epoch {epoch+1}/{params['n_epochs']}\")\n",
    "\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            log_preds = model(imgs)\n",
    "            loss = loss_fn(log_preds, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += ((1 / (step + 1)) * (loss.data.item() - train_loss))\n",
    "\n",
    "            pbar.set_postfix(loss=loss.data.item())\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation\n",
    "    valid_loss = 0\n",
    "    actual_labels = []\n",
    "    pred_labels = []\n",
    "    model.eval()\n",
    "    with tqdm(enumerate(valid_loader), total=len(valid_loader), unit=\"batch\") as pbar:\n",
    "        for step, (imgs, labels) in pbar:\n",
    "            pbar.set_description(f\"Epoch {epoch+1}/{params['n_epochs']}\")  \n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            log_preds = model(imgs)\n",
    "            loss = loss_fn(log_preds, labels)\n",
    "            preds = probs(log_preds)\n",
    "\n",
    "            valid_loss+=((1 / (step + 1)) * (loss.data.item() - valid_loss))\n",
    "\n",
    "            # Calculate accuracy\n",
    "            top_prob, top_class = preds.topk(1, dim=1)\n",
    "            pred_labels+= list((top_class.view(-1)).cpu().numpy())\n",
    "            actual_labels+= list(labels.cpu().numpy())\n",
    "\n",
    "            pbar.set_postfix(loss=loss.data.item())\n",
    "\n",
    "        correct = ((np.array(pred_labels)==np.array(actual_labels)).sum())\n",
    "        total = len(valid_dataset)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        tqdm.write(\"Epoch {} avg Valid loss: {:.3f}\".format(epoch + 1, valid_loss))\n",
    "        tqdm.write(\"Epoch {} Valid accuracy: {:.1%} ({} of {} right)\\n\".format(epoch + 1, accuracy, correct, total))\n",
    "\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_acc.append(accuracy)\n",
    "\n",
    "    # Save model if validation loss is the lowest\n",
    "    if len(valid_losses)>1 and (valid_loss<min(valid_losses[:-1])):\n",
    "        torch.save(model.state_dict(), f\"models/{params['lr']}_{params['image_size']}_{params['n_epochs']}_{params['dropout_rate']}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(range(1, params[\"n_epochs\"]+1), train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(1, params[\"n_epochs\"]+1), valid_losses, label=\"Validation Loss\")\n",
    "plt.plot(range(1, params[\"n_epochs\"]+1), valid_acc, label=\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"models/{params['lr']}_{params['image_size']}_{params['n_epochs']}_{params['dropout_rate']}.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:38<00:00,  2.06batch/s, loss=0.0357]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.028\n",
      "Valid accuracy: 99.0% (4949 of 5000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "running_loss = 0\n",
    "actual_labels = []\n",
    "pred_labels = []\n",
    "with tqdm(enumerate(valid_loader), total=len(valid_loader), unit=\"batch\") as pbar:\n",
    "    for step, (imgs, labels) in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        log_preds = model(imgs)\n",
    "        loss = loss_fn(log_preds, labels)\n",
    "\n",
    "        preds = probs(log_preds)\n",
    "        running_loss += ((1 / (step + 1)) * (loss.data.item() - running_loss))\n",
    "\n",
    "        # Calculate accuracy\n",
    "        top_prob, top_class = preds.topk(1, dim=1)\n",
    "        pred_labels += list((top_class.view(-1)).cpu().numpy())\n",
    "        actual_labels += list(labels.cpu().numpy())\n",
    "\n",
    "        pbar.set_postfix(loss=loss.data.item())\n",
    "\n",
    "    correct = ((np.array(pred_labels)==np.array(actual_labels)).sum())\n",
    "    total = len(actual_labels)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    tqdm.write(\"Valid loss: {:.3f}\".format(running_loss))\n",
    "    tqdm.write(\"Valid accuracy: {:.1%} ({} of {} right)\\n\".format(accuracy, correct, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class for test data\n",
    "class TestCatDogDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image_filename = Path(image_filepath).stem\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, image_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestCatDogDataset(test_image_paths, validation_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=params[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:06<00:00, 73.13batch/s]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "pred_labels = []\n",
    "filename = []\n",
    "with tqdm(test_loader, total=len(test_loader), unit=\"batch\") as pbar:\n",
    "    for imgs, filenames in pbar:\n",
    "        imgs = imgs.to(device)\n",
    "        log_preds = model(imgs)\n",
    "\n",
    "        preds = probs(log_preds)\n",
    "\n",
    "        top_prob, top_class = preds.topk(1, dim=1)\n",
    "        pred_labels += list((top_class.view(-1)).cpu().numpy())\n",
    "        filename += filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(filename, pred_labels)),\n",
    "               columns=[\"id\", \"label\"])\n",
    "df[\"id\"] = pd.to_numeric(df[\"id\"])\n",
    "df = df.sort_values(by=[\"id\"])\n",
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. CIFAR-10 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((params[\"image_size\"], params[\"image_size\"])),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "validation_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((params[\"image_size\"], params[\"image_size\"])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=params[\"batch_size\"],\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=params[\"num_workers\"])\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=False,\n",
    "                                       download=True, transform=validation_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=params[\"batch_size\"],\n",
    "                                         shuffle=False, num_workers=params[\"num_workers\"])\n",
    "\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(cat_dog_model)\n",
    "model.classifier = torch.nn.Sequential(torch.nn.Linear(25088, 4096),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Dropout(p=params[\"dropout_rate\"]),\n",
    "                                       torch.nn.Linear(4096, 4096),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Dropout(p=params[\"dropout_rate\"]),\n",
    "                                       torch.nn.Linear(4096, 10))\n",
    "model.to(device)\n",
    "\n",
    "probs = torch.nn.Softmax(dim=1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.classifier.parameters(), lr=params[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 782/782 [04:02<00:00,  3.23batch/s, loss=1.63]\n",
      "Epoch 1/10: 100%|██████████| 157/157 [00:47<00:00,  3.32batch/s, loss=1.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 avg Valid loss: 1.543\n",
      "Epoch 1 Valid accuracy: 68.6% (6857 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 782/782 [03:58<00:00,  3.27batch/s, loss=1.21]\n",
      "Epoch 2/10: 100%|██████████| 157/157 [00:46<00:00,  3.35batch/s, loss=0.879]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 avg Valid loss: 0.899\n",
      "Epoch 2 Valid accuracy: 76.6% (7656 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 782/782 [03:58<00:00,  3.28batch/s, loss=1.01]\n",
      "Epoch 3/10: 100%|██████████| 157/157 [00:45<00:00,  3.44batch/s, loss=0.633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 avg Valid loss: 0.670\n",
      "Epoch 3 Valid accuracy: 79.4% (7944 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 782/782 [03:53<00:00,  3.34batch/s, loss=0.527]\n",
      "Epoch 4/10: 100%|██████████| 157/157 [00:46<00:00,  3.39batch/s, loss=0.513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 avg Valid loss: 0.568\n",
      "Epoch 4 Valid accuracy: 81.6% (8156 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 782/782 [03:56<00:00,  3.31batch/s, loss=0.786]\n",
      "Epoch 5/10: 100%|██████████| 157/157 [00:45<00:00,  3.42batch/s, loss=0.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 avg Valid loss: 0.516\n",
      "Epoch 5 Valid accuracy: 83.0% (8300 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 782/782 [03:54<00:00,  3.33batch/s, loss=0.194]\n",
      "Epoch 6/10: 100%|██████████| 157/157 [00:46<00:00,  3.41batch/s, loss=0.385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 avg Valid loss: 0.479\n",
      "Epoch 6 Valid accuracy: 83.7% (8374 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 782/782 [03:58<00:00,  3.28batch/s, loss=0.913]\n",
      "Epoch 7/10: 100%|██████████| 157/157 [00:46<00:00,  3.40batch/s, loss=0.368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 avg Valid loss: 0.455\n",
      "Epoch 7 Valid accuracy: 84.2% (8425 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 782/782 [03:57<00:00,  3.29batch/s, loss=0.444]\n",
      "Epoch 8/10: 100%|██████████| 157/157 [00:47<00:00,  3.33batch/s, loss=0.335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 avg Valid loss: 0.436\n",
      "Epoch 8 Valid accuracy: 84.8% (8483 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 782/782 [03:56<00:00,  3.30batch/s, loss=0.348]\n",
      "Epoch 9/10: 100%|██████████| 157/157 [00:46<00:00,  3.41batch/s, loss=0.321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 avg Valid loss: 0.422\n",
      "Epoch 9 Valid accuracy: 85.6% (8556 of 10000 right)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 782/782 [04:00<00:00,  3.25batch/s, loss=0.336]\n",
      "Epoch 10/10: 100%|██████████| 157/157 [00:46<00:00,  3.34batch/s, loss=0.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 avg Valid loss: 0.411\n",
      "Epoch 10 Valid accuracy: 85.9% (8587 of 10000 right)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "valid_acc = []\n",
    "for epoch in range(params[\"n_epochs\"]):\n",
    "    # Train\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    with tqdm(enumerate(train_loader), total=len(train_loader), unit=\"batch\") as pbar:\n",
    "        for step, (imgs, labels) in pbar:\n",
    "            pbar.set_description(\"Epoch {}/{}\".format(epoch+1, params[\"n_epochs\"]))\n",
    "\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            log_preds = model(imgs)\n",
    "            loss = loss_fn(log_preds, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += ((1 / (step + 1)) * (loss.data.item() - train_loss))\n",
    "\n",
    "            pbar.set_postfix(loss=loss.data.item())\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation\n",
    "    valid_loss = 0\n",
    "    actual_labels = []\n",
    "    pred_labels = []\n",
    "    model.eval()\n",
    "    with tqdm(enumerate(test_loader), total=len(test_loader), unit=\"batch\") as pbar:\n",
    "        for step, (imgs, labels) in pbar:\n",
    "            pbar.set_description(f\"Epoch {epoch+1}/{params['n_epochs']}\")  \n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            log_preds = model(imgs)\n",
    "            loss = loss_fn(log_preds, labels)\n",
    "\n",
    "            preds = probs(log_preds)\n",
    "            valid_loss+=((1 / (step + 1)) * (loss.data.item() - valid_loss))\n",
    "\n",
    "            # Calculate accuracy\n",
    "            top_prob, top_class = preds.topk(1, dim=1)\n",
    "            pred_labels+= list((top_class.view(-1)).cpu().numpy())\n",
    "            actual_labels+= list(labels.cpu().numpy())\n",
    "\n",
    "            pbar.set_postfix(loss=loss.data.item())\n",
    "\n",
    "        correct = (np.array(pred_labels)==np.array(actual_labels)).sum()\n",
    "        total = len(actual_labels)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        tqdm.write(\"Epoch {} avg Valid loss: {:.3f}\".format(epoch + 1, valid_loss))\n",
    "        tqdm.write(\"Epoch {} Valid accuracy: {:.1%} ({} of {} right)\\n\".format(epoch + 1, accuracy, correct, total))\n",
    "\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_acc.append(accuracy)\n",
    "\n",
    "    if len(valid_losses)>1 and (valid_loss<min(valid_losses[:-1])):\n",
    "        torch.save(model.state_dict(), f\"models/cifar_10_{params['lr']}_{params['image_size']}_{params['n_epochs']}_{params['dropout_rate']}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(range(1, params[\"n_epochs\"]+1), train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(1, params[\"n_epochs\"]+1), valid_losses, label=\"Validation Loss\")\n",
    "plt.plot(range(1, params[\"n_epochs\"]+1), valid_acc, label=\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. CIFAR-10 testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"models/cifar_10_{params['lr']}_{params['image_size']}_{params['n_epochs']}_{params['dropout_rate']}.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:47<00:00,  3.32batch/s]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "model.eval()\n",
    "\n",
    "with tqdm(test_loader, total=len(test_loader), unit=\"batch\") as pbar:\n",
    "    for imgs, labels in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        log_preds = model(imgs)\n",
    "        loss = loss_fn(log_preds, labels)\n",
    "\n",
    "        preds = probs(log_preds)\n",
    "\n",
    "        top_prob, top_class = preds.topk(1, dim=1)\n",
    "\n",
    "        for label, prediction in zip(labels, top_class):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plane': 864, 'car': 929, 'bird': 777, 'cat': 735, 'deer': 844, 'dog': 808, 'frog': 908, 'horse': 882, 'ship': 926, 'truck': 914}\n",
      "{'plane': 1000, 'car': 1000, 'bird': 1000, 'cat': 1000, 'deer': 1000, 'dog': 1000, 'frog': 1000, 'horse': 1000, 'ship': 1000, 'truck': 1000}\n"
     ]
    }
   ],
   "source": [
    "print(correct_pred)\n",
    "print(total_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class plane is: 86.4 %\n",
      "Accuracy for class car   is: 92.9 %\n",
      "Accuracy for class bird  is: 77.7 %\n",
      "Accuracy for class cat   is: 73.5 %\n",
      "Accuracy for class deer  is: 84.4 %\n",
      "Accuracy for class dog   is: 80.8 %\n",
      "Accuracy for class frog  is: 90.8 %\n",
      "Accuracy for class horse is: 88.2 %\n",
      "Accuracy for class ship  is: 92.6 %\n",
      "Accuracy for class truck is: 91.4 %\n",
      "Test accuracy: 85.9% (8587 of 10000 right)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname, accuracy))\n",
    "\n",
    "correct = sum(correct_pred.values())\n",
    "total = sum(total_pred.values())\n",
    "accuracy = correct / total\n",
    "\n",
    "print(\"Test accuracy: {:.1%} ({} of {} right)\\n\".format(accuracy, correct, total))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89ea3e921d5f22d2b46ed8b2b66b1aa063d1552fc9c096c0e74c45a505ca44a9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
